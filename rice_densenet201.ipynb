{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['labelledrice']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Imports\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '../input/labelledrice/Labelled/'","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define transforms for the training and validation sets\ndata_transforms ={\n    \"train_transforms\": transforms.Compose([transforms.RandomRotation(30),\n                                           transforms.RandomResizedCrop(224),\n                                           transforms.RandomHorizontalFlip(),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])]),\n   \"valid_transforms\": transforms.Compose([transforms.Resize(225),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])]), \n    \"test_transforms\": transforms.Compose([transforms.Resize(225),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])])\n}","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the dataset into train, validation and test\ntrain_data = 0.8\nvalid_data = 0.1\ntest_data = 0.1\n\n# Load the datasets with ImageFolder\ntrain_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])\nvalid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\ntest_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"test_transforms\"])\n\n# Obtain training indices that will be used for validation and test\nnum_train = len(train_data)\nindices = list(range(num_train))\n# np.random.shuffle(indices)\ntrain_count = int(0.8*num_train)\nvalid_count = int(0.1*num_train)\ntest_count = num_train - train_count - valid_count\ntrain_idx = indices[:train_count]\nvalid_idx = indices[train_count:train_count+valid_count]\ntest_idx = indices[train_count+valid_count:]\n\nprint(len(train_idx), len(valid_idx), len(test_idx))\nprint(\"Training\", train_count, np.sum(len(train_idx)/num_train))\nprint(\"Validation\", valid_count, np.sum(len(valid_idx)/num_train))\nprint(\"Test\", test_count, np.sum(len(test_idx)/num_train))","execution_count":5,"outputs":[{"output_type":"stream","text":"2684 335 336\nTraining 2684 0.8\nValidation 335 0.09985096870342772\nTest 336 0.10014903129657228\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define a custom sampler for the dataset loader avoiding recreating the dataset (just creating a new loader for each different sampling)\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\ntest_sampler = SubsetRandomSampler(test_idx)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the dataloaders using the image datasets\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = 32, sampler = test_sampler)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=['LeafBlast', 'BrownSpot', 'Healthy', 'Hispa']","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify model architecture\n# Load the pretrained model from pytorch\nmodel_transfer = models.densenet201(pretrained=True)\n\n# Check if GPU is available\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    model_transfer = model_transfer.cuda()","execution_count":9,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /tmp/.cache/torch/checkpoints/densenet201-c1103571.pth\n100%|██████████| 81131730/81131730 [00:00<00:00, 97472952.82it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Freeze training for all 'features' layers\nfor param in model_transfer.features.parameters():\n    param.requires_grad=False","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total image label\n\nn_inputs = model_transfer.classifier.in_features\n\n# Add last linear layer (n_inputs -> 2 classes)\n# New layer automatically has requires_grad = True\nlast_layer = nn.Linear(n_inputs, len(classes))\n\nmodel_transfer.classifier = last_layer\n\n# If GPU is available, move the model to GPU\nif use_cuda:\n    model_transfer = model_transfer.cuda()\n  \n# Check to see the last layer produces the expected number of outputs\nprint(model_transfer.classifier.out_features)","execution_count":11,"outputs":[{"output_type":"stream","text":"4\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Specify loss function and optimizer\ncriterion_transfer = nn.CrossEntropyLoss()\noptimizer_transfer = optim.SGD(model_transfer.classifier.parameters(), lr=0.01, momentum = 0.9)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train the model\ndef train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    '''returns trained model'''\n    # Initialize tracker for minimum validation loss\n    valid_loss_min = np.inf\n  \n    for epoch in range(1, n_epochs+1):\n        # Initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n    \n        # Model training\n        model.train()\n        for batch_idx, (data,target) in enumerate(trainloader):\n            # Move to GPU\n            if use_cuda:\n                data,target = data.cuda(), target.cuda()\n      \n            # Clear the gradient of all optimized variables\n            optimizer.zero_grad()\n            # Forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # Calculate the batch loss\n            loss = criterion(output, target)\n            # Backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # Perform a single optimization step (parameter update)\n            optimizer.step()\n            # Record the average training loss\n            train_loss = train_loss + ((1/ (batch_idx + 1 ))*(loss.data-train_loss))\n      \n        # Model validation\n        model.eval()\n        for batch_idx, (data,target) in enumerate(validloader):\n            # Move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # Update the average validation loss\n            # Forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # Calculate the batch loss\n            loss = criterion(output, target)\n            # Update the average validation loss\n            valid_loss = valid_loss + ((1/ (batch_idx +1)) * (loss.data - valid_loss))\n      \n        # print training/validation stats\n        print('Epoch: {} \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f}'.format(\n            epoch,\n            train_loss,\n            valid_loss))\n    \n        # Save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.5f} --> {:.5f}). Saving model ...'.format(\n                  valid_loss_min,\n                  valid_loss))\n            torch.save(model.state_dict(), 'model_transfer.pt')\n            valid_loss_min = valid_loss\n  \n    # Return trained model\n    return model\n\n# Define loaders transfer\nloaders_transfer = {'train': trainloader,\n                    'valid': validloader,\n                    'test': testloader}\n\n# Train the model\nmodel_transfer = train(10, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch: 1 \tTraining Loss: 1.08242 \tValidation Loss: 0.86331\nValidation loss decreased (inf --> 0.86331). Saving model ...\nEpoch: 2 \tTraining Loss: 0.95436 \tValidation Loss: 1.00060\nEpoch: 3 \tTraining Loss: 0.95257 \tValidation Loss: 0.75948\nValidation loss decreased (0.86331 --> 0.75948). Saving model ...\nEpoch: 4 \tTraining Loss: 0.92095 \tValidation Loss: 1.20422\nEpoch: 5 \tTraining Loss: 0.89899 \tValidation Loss: 2.26074\nEpoch: 6 \tTraining Loss: 0.94515 \tValidation Loss: 1.58188\nEpoch: 7 \tTraining Loss: 0.92261 \tValidation Loss: 1.78734\nEpoch: 8 \tTraining Loss: 0.95561 \tValidation Loss: 2.81426\nEpoch: 9 \tTraining Loss: 0.92340 \tValidation Loss: 1.27486\nEpoch: 10 \tTraining Loss: 0.92716 \tValidation Loss: 2.00708\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the model that got the best validation accuracy\nmodel_transfer.load_state_dict(torch.load('model_transfer.pt'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model_transfer.eval()\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n        100. * correct / total, correct, total))\n\n# call test function    \ntest(loaders_transfer, model_transfer, criterion_transfer, use_cuda)","execution_count":23,"outputs":[{"output_type":"stream","text":"Test Loss: 1.762245\n\n\nTest Accuracy: 34% (116/336)\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}